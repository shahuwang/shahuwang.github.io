这是 Russ Cox 的三篇正则系列中的第一篇，我看了觉得很有用，而且解说得很好，所以就决定翻译过来了。文章比较长，所以我分成两篇来翻译，这是第二篇。本文介绍的概念，只要稍微学习过可计算理论和编译原理，就能够明白的。文章结尾部分我实在是懒得翻译了，这篇文章翻译了我一个星期，够累人的

* * *

###### 实现

Thompson 在他 1968 年的论文里介绍了一种多状态模拟的方法。在他的方法里，NFA 的状态是用机器码序列进行表示的，一组可选状态，其实就是一组函数调用指令。本质上，Thompson 聪明的将正则表达式转换为机器码。四十年后，计算机已经变得快了许多，所以已经不需要继续使用机器码了。接下来的部分介绍了用可移植的 ANSI C 的实现。所有的代码（不超过400行），以及性能测试脚本都可以从网上[获取到](http://swtch.com/~rsc/regexp/)

###### 实现：编译为 NFA

第一步是将正则表达式编译为等价的 NFA。在我们的 C 程序里面，我们将会用一个State数据结构的链接集合来表示一个 NFA：

<!--more-->

    struct State
    {
        int c;
        State *out;
        State *out1;
        int lastlist;
    };

每个状态都代表着如下的 NFA 片段之一，代表哪个主要取决于 c 的值。

![NFA 片段](http://pdos.csail.mit.edu/~rsc/regexp-img/fig13.png)

(Lastlist 是在状态机执行的过程中使用的，下文会进行解释）

按照 Thompson 的论文，编译器将正则表达式转换为后缀表达式，然后使用点号(.)来表示明确的串联操作符。一个单独的函数 re2post 将中缀表达式如 "a(bb)+a" 重写为等价的后缀表达式 "abb.+.a"。(这个真实的实现里，点号其实是作为匹配任意字符的元字符，而不是串联操作符。同时，真实的实现里，一般是在解析正则表达式的过程中就构建好了 NFA，而不是先转换为后缀表达式。然而，后缀表达式这种方式比较方便，而且与 Thompson 的论文更加接近。）

在编译器扫描后缀表达式的过程中，它保持着一个栈，用来存储计算过的 NFA 片段。遇到字面值（Literal）则推一个 NFA 片段到栈中。而当遇着操作符的时候，则先从栈顶推出一个片段，与操作符计算后，重新推入一个新的片段。比如，在编译完 abb.+.a 中的 abb 之后，这个栈已经有了对应 a, b, 和 b 的 NFA 片段。然后在编译 . 的时候，需要从栈中推出两个 b 对应的 NFA 片段，然后构成一个新的 NFA 片段 bb. 并推回到栈中去。每一个 NFA 片段都由其开始状态和出发箭头构成：

    struct Frag
    {
        State *start;
        Ptrlist *out;
    };

Start 指向片段的开始状态，out则是还没有连接上任何东西的指向 State类型指针的列表，这些都是 NFA 片段的尾出箭头来的。

有几个函数则是用来操作指针列表的：

    Ptrlist *list1(State **outp);
    Ptrlist *append(Ptrlist *l1, Ptrlist *l2);
    void patch(Ptrlist *l, State *s);

list1 创建一个指针列表，仅包含单个指针 outp。append 则连接两个指针列表，并返回结果。patch 将指针列表里的尾箭头都指向指针 s, 其令指针列表里的每个指针 outp : *outs = s。

有了这些原语和栈片段，编译器只需简单循环读入后缀表达式。在最后，栈中就只会有一个片段，然后把这个片段与匹配状态缝接起来，就完全了一个 NFA 了。

    State*
    post2nfa(char *postfix)
    {
        char *p;
        Frag stack[1000], *stackp, e1, e2, e;
        State *s;

        #define push(s) *stackp++ = s
        #define pop()   *--stackp

        stackp = stack;
        for(p=postfix; *p; p++){
            switch(*p){
            /* compilation cases, described below */
            }
        }

        e = pop();
        patch(e.out, matchstate);
        return e.start;
    }

如下这些步骤模仿上面描述的这些转换。

字面值：

    default:
    s = state(*p, NULL, NULL);                 
    push(frag(s, list1(&s->out));
    break;

![默认](http://pdos.csail.mit.edu/~rsc/regexp-img/fig14.png)

串联：

    case '.':
    e2 = pop();
    e1 = pop();
    patch(e1.out, e2.start);
    push(frag(e1.start, e2.out));
    break;

![串联](http://pdos.csail.mit.edu/~rsc/regexp-img/fig15.png)

并联：

    case '|':
    e2 = pop();
    e1 = pop();
    s = state(Split, e1.start, e2.start);
    push(frag(s, append(e1.out, e2.out)));
    break;

![并联](http://pdos.csail.mit.edu/~rsc/regexp-img/fig16.png)

零个或一个：

    case '?':
    e = pop();
    s = state(Split, e.start, NULL);
    push(frag(s, append(e.out, list1(&s->out1))));
    break;

![零个或一个](http://pdos.csail.mit.edu/~rsc/regexp-img/fig17.png)

零个或多个：

    case '*':
    e = pop();
    s = state(Split, e.start, NULL);
    patch(e.out, s);
    push(frag(s, list1(&s->out1)));
    break;

![零个或多个](http://pdos.csail.mit.edu/~rsc/regexp-img/fig18.png)

一个或多个:

    case '+':
    e = pop();
    s = state(Split, e.start, NULL);
    patch(e.out, s);
    push(frag(e.start, list1(&s->out1)));
    break;

![一个或多个](http://pdos.csail.mit.edu/~rsc/regexp-img/fig19.png)

###### 实现：模拟 NFA

现在 NFA 已经被创建了，我们需要来模拟它。模拟过程需要追踪状态列表，我们将这些状态存储到一个 array list 里面去：

    struct List
    {
        State **s;
        int n;
    };

模拟过程使用到两个列表：clist 用来装当前 NFA 所在的状态， nlist 用来装 NFA 即将进入的状态。循环过程中，clist 先初始化为仅有一个开始状态，然后每次一步。

    int
    match(State *start, char *s)
    {
        List *clist, *nlist, *t;

        /* l1 and l2 are preallocated globals */
        clist = startlist(start, &l1);
        nlist = &l2;
        for(; *s; s++){
            step(clist, *s, nlist);
            t = clist; clist = nlist; nlist = t;    /* swap clist, nlist */
        }
        return ismatch(clist);
    }

为了避免在循环迭代中每次都要重新分配两个列表，match 方法里使用了两个实现分配好的列表 l1 和 l2 作为 clist 和 nlist，每一步完成后都对这两个进行交换.

    int
    ismatch(List *l)
    {
        int i;

        for(i=0; i<l->n; i++)
            if(l->s[i] == matchstate)
                return 1;
        return 0;
    }

addstate 方法增加一个状态到列表里面，但如果其之前已经在列表里了，就不再加入。每次添加状态的时候都扫描一次全列表，会非常低效，所以用 listid 这个变量作为一个列表生成数字，当添加一个状态到列表里的时候，先判断一下 listid 是否等于 s->lastlist 。如果相等，表明之前已经添加过这个状态了。如果不等，令 s->lastlist = listid,然后添加到列表里。 addstate 同样会处理空箭头，如果 s 是一个 split 状态，其有两个空箭头指向新的状态，addstate 会把这些状态添加到列表里，而不是添加 s (译注：这里的split状态，可以参考上面提到的并联部分处理的代码，split就类似于并联)。

    void
    addstate(List *l, State *s)
    {
        if(s == NULL || s->lastlist == listid)
            return;
        s->lastlist = listid;
        if(s->c == Split){
            /* follow unlabeled arrows */
            addstate(l, s->out);
            addstate(l, s->out1);
            return;
        }
        l->s[l->n++] = s;
    }

startlist 方法初始化一个状态列表，并把开始状态添加到里面去：

    List*
    startlist(State *s, List *l)
    {
        listid++;
        l->n = 0;
        addstate(l, s);
        return l;
    }

最后，step 方法接受一个输入字符，随着 NFA 前进，用当前的状态列表 clist 去计算出下一状态列表 nlist:

    void
    step(List *clist, int c, List *nlist)
    {
        int i;
        State *s;

        listid++;
        nlist->n = 0;
        for(i=0; i<clist->n; i++){
            s = clist->s[i];
            if(s->c == c)
                addstate(nlist, s->out);
        }
    }

###### 性能

上面这个 C 的实现并没有去注意性能问题。尽管如此，一个较慢的线性时间算法实现，还是要比一个认真实现的指数时间的算法要好得多。一个失控正则就能够很好的说明问题了。

我们来看 $$$a?^na^n$$$ 这个正则表达式，如果 a? 这个正则在运行的时候，做出的选择是不匹配，那么就会让全部的字符串由 $$$a^n$$$ 匹配。回溯的正则，在实现零个或一个匹配这种情况的时候，是优先尝试匹配一个，失败了再尝试0个。此时有 n 个这样的选择（译注：$$$a?^n$$$ 表示 a? 出现 n 次），加起来就有 $$$2^n$$$ 种可能性。此时，只有当所有的选择最后到只剩下选择匹配零个的时候，这个正则匹配才能完成。回溯的方法需要的时间是 $$$O(2^n)$$$ ,所以当 n 超过25的时候，那是已经不可能完成了。

相反，Thompson 的算法，保持一个状态列表，长度最大为 n，然后处理长度为 n 的字符串的时候，时间大约为 $$$O(n^2)$$$。（运行时间是超线性的，因为我们在输入增长的时候，并没有保留着正则实例————译注：表示没看懂这句话的意思）

下图展示了用正则 $$$a?^na^n$$$ 匹配 $$$a^n$$$ 所需要的时间情况：

![时间对比](http://pdos.csail.mit.edu/~rsc/regexp-img/grep1p.png)

注意 y 轴上的是指数刻度，这样可以看到一个更大范围的时间。

从图中可以看得很清楚，Perl, PCRE, Python, 和 Ruby 都使用了递归回溯。 PCRE 在 n=23 的时候就停止了，因为在递归深度超过一定数量之后，其就自动停止了。对于 Perl 5.6, 它们说其正则的递归回溯搜索是进行过 [memoize](http://perlmonks.org/index.pl?node_id=502408) (译注：这个词是 Perl 的术语，应该是用空间换时间的意思)，多耗了些内存，以避免在非回溯的时候出现指数时间。但是根据上图来看，很显然这个 memoization 并没有完成， Perl 的运行时间还是指数增长，即使在没有回溯的情况下也是如此。尽管这里没有进行性能测试，Java 其实也是用了回溯的实现。实际上，java.util.regex 接口需要一个回溯的实现，因为任意的 Java 代码能够替换为匹配路径（译注：没搞明白这句话的意思）。PHP 则是使用了 PCRE 这个库。

粗蓝色的线是上面那个 C 语言实现的 Thompson 算法。 Awk, Tcl, GNU grep, 和 GNU awk 则是构建了 DFA，有的是预先构建好，有的则是在在运行中构建。下面将会谈到如何在运行中构建 DFA。

有些人可能会说这些测试对回溯的实现很不公平，因为它并没有去关注回溯实现里比较常用的那些例子。但是这个争执则没搞明白这点：让你在这两者中做一个选择，一个的运行时间是可预见的，始终一致的，快速的。而另一个大部分时候都运行得很快，但是有些输入，则会耗费一年的时候，甚至更长。该做出怎样的选择已经很明显了。另外，尽管这个令人惊讶的情况很少会在现实中出现，但是还是有一些情况会经常出现，让人也很惊讶的。比如使用 (._) (._) (.*) (._) (._) 来分割五个空格隔开的字段，或者使用串联的时候，常见的情况并没有最先出现。结果，程序员们必须知道那种构造不实用，或者得向优化高手请教。使用 Thompson 的 NFA 模拟算法，则不需要这些调整，因为它永远不会出现失控正则。

###### 缓存 NFA 构建一个 DFA

DFA 比 NFA 更加高效，因为在任何一个状态，任何一个时间，其都仅有一个下一状态。 任何一个 NFA 都可以转换为一个等价的 DFA。

比如，下图是对应正则 abab|abbb 的 NFA：

![NFA](http://pdos.csail.mit.edu/~rsc/regexp-img/fig20.png)

等价的 DFA 如下：

![DFA](http://pdos.csail.mit.edu/~rsc/regexp-img/fig21.png)

其实对比来看，一个 DFA 状态，就是对应一组 NFA 的状态。从这个角度上说， Thompson 的 NFA 模拟算法，实际上执行的是等价的 DFA。 每步完成后，为避免重复计算，我们可以在空闲的内存里缓存这个列表。基于之前的 NFA 实现，我们只需不到 100 行代码就可以构建一个 DFA 的实现了。

为了创建缓存，首先引入一个新的数据类型来表示 DFA 的状态：

    struct DState
    {
        List l;
        DState *next[256];
        DState *left;
        DState *right;
    };

一个 DState 是一份 list l 复制过来的缓存，next 数组保存的是每个可能输入的对应状态：如果当前的状态是 d， 下一个输入是 c， 则 d->next[c]是下一个状态。如果 d-> next[c] 是null， 则说明下一个状态还没有被计算出来。输入一个状态，和一个字符，nextstate 计算，记录和返回下一个状态。

正则匹配其实是不停重复 d->next[c]这一过程的，同时在需要的时候，就调用 nextstate 函数来计算新的状态。

    int
    match(DState *start, char *s)
    {
        int c;
        DState *d, *next;

        d = start;
        for(; *s; s++){
            c = *s & 0xFF;
            if((next = d->next[c]) == NULL)
                next = nextstate(d, c);
            d = next;
        }
        return ismatch(&d->l);
    }

所以被计算过的 DState 都需要存储这一个可以通过 DState 的 list 找到 DState 的结构里。为了做到这点，我们使用排序过的列表作为key，将他们放在二叉树里。 dstate 函数接受一个列表输入，返回对应的 DState，如果需要的时候，则分配一个。

    DState*
    dstate(List *l)
    {
        int i;
        DState **dp, *d;
        static DState *alldstates;

        qsort(l->s, l->n, sizeof l->s[0], ptrcmp);

        /* look in tree for existing DState */
        dp = &alldstates;
        while((d = *dp) != NULL){
            i = listcmp(l, &d->l);
            if(i < 0)
                dp = &d->left;
            else if(i > 0)
                dp = &d->right;
            else
                return d;
        }

        /* allocate, initialize new DState */
        d = malloc(sizeof *d + l->n*sizeof l->s[0]);
        memset(d, 0, sizeof *d);
        d->l.s = (State**)(d+1);
        memmove(d->l.s, l->s, l->n*sizeof l->s[0]);
        d->l.n = l->n;

        /* insert in tree */
        *dp = d;
        return d;
    }

nextstate 执行 NFA 的step，然后返回对应的 dstate：

    DState*
    nextstate(DState *d, int c)
    {
        step(&d->l, c, &l1);
        return d->next[c] = dstate(&l1);
    }

最终， DFA 的开始状态，就是对应于 NFA 的开始状态列表的 DState：

    DState*
    startdstate(State *start)
    {
        return dstate(startlist(start, &l1));
    }

（在 NFA 的模拟里面， l1 是预先分配好的）

DState 对应 DFA 的状态， 但是 DFA 只有在需要的时候才进行创建：如果一个 DFA 状态并没有在搜索的过程中遇到，它就不存在于缓存之中。（译注：表示还没有看明白这句话的意思）一个可行的方法是马上计算出整个 DFA 出来， 这样做可以让匹配更加快一点，因为一些分支被去除掉了。但是在开始的时候会耗费一些时间和空间。

有人会担心在运行时构建 DFA 会使内存占用暴涨，但是由于 DState 仅仅是缓存 step 函数，dstate 的实现可以在缓存变得过大的时候抛弃整个 DFA 。这个缓存替换规则，只需要在 dstate 和 nextstate 函数里增加几行代码，整个内存管理的代码加起来不到 50 行。这里有一个[实现](http://swtch.com/~rsc/regexp/)。（Awk 使用了一个类似的内存限制的缓存策略，仅保留 32 个 缓存的状态。这解释了它在 n=28 是性能测试的非线性变化。）

派生于正则的 NFA 表现出良好的局部性：在处理大部分数据的时候，他们访问同一个状态，遵循同样的转移箭头一次又一次重复。这让做缓存是很值得的：一个箭头第一次跟追随的时候，NFA 对应的下一个状态需要计算，但是此后就仅仅是内存访问而已。 真实的 DFA 实现，还会使用更多的优化手段来令匹配更加快速。本文的姊妹篇将会介绍基于 DFA 实现的正则表达式的更多细节。

真实世界的正则实现

在生产环境中使用的正则表达式远比上面实现的那个正则引擎能处理的情况复杂得多。本节主要简单描述一下一些共通的复杂度，完整的介绍已经超过了一篇介绍性文章的范围。

字符集合：一个字符集，无论是[0-9] 还是 \w 或者 . (点号), 都仅仅是一个替代的简明表示。这些字符集可以在编译过程中展开为其替代的内容，不过添加一个它们完整明确表示新的 NFA 节点会更加有效。POSIX 定义了一些特殊的字符集，如 [[:upper:]] ，会根据当前的区域改变其意义，达到这个目标最难的不是把它们的意义编码为 NFA，而是确定他们的意义。

转义序列&nbsp;真正的转义序列需要处理转义序列，比如要匹配一些元字符如\( , \) ，\\ 等。另外还有能匹配一些打不出来的字符，如换行符\n

重复计数&nbsp;很多正则引擎都提供了重复计数操作符，如{n} 表示匹配 n 次，{n,m} 匹配最少 n 次，且不超过 m 次。而{n,} 则表示匹配 n 次或者更多。递归的回溯正则实现可以用一个循环实现重复计数。而基于 NFA 或者 DFA 的实现则必须将重复计数展开，如 e{3} 展开为 eee, e{3,5} 展开为 eeee?e?, e{3,} 则展开为 eee+.

子匹配提取&nbsp;当正则用来进行字符串财富或者解析的时候，能找出输入字符串的哪一部分被哪个子正则匹配了，还是很有用的。很多正则引擎可以提取出括号括起来的子正则匹配的字符串，如在 Perl 里，使用如下正则，可以分部分提取出输入字符串（日期和时间字符串）中各个部分的内容：

if(/([0-9]+-[0-9]+-[0-9]+) ([0-9]+:[0-9]+)/){ print "date: $1, time: $2\n"; }

子匹配边界的提取一直是被计算机科学理论所忽视的，而它也是很多正则引擎使用递归回溯最主要的原因。不过，Thompson 这类型的算法是可以在不影响性能的情况下，调整为可追踪子匹配边界的算法。在早至 1985 年的时候，第八版的 regexp(3) 已经实现了一个这样的算法，不过并没有广泛使用，甚至很少被提起过，下文将会对它进行说明。

不固定匹配（unanchored match)&nbsp;本文都假设正则是和整个的输入字符串对应匹配的，但现实中，我们更需要的是找出输入字符串中被正则匹配的部分。Unix 的工具一般都返回的是从最左起的最长匹配。对 e 的不固定搜索，其实是特殊的子匹配提取，它其实和 .*(e).* （.*限制为只匹配最短）这个正则是一样的。

非贪心操作符在传统的 Unix 正则里，重复操作符 ?, * 和 + 都是最大最多匹配的，比如用(.+)(.+) 去匹配 abcd 的时候，第一个 (.+) 会匹配完 abc，然后第二个会匹配 d。这些操作符称之为贪心操作符。Perl 引进了 ??, *? 和 +? 作为非贪心操作符，它们会尽可能少匹配，如(.+?)(.+?) 去匹配 abcd 的时候，第一个 (.+?) 会匹配一个 a，第二个则会匹配bcd。根据定义，贪心非贪心，都不用影响一个正则是否匹配一个字符串，只会影响括号括起来的子正则匹配的情况。在回溯算法里使用过一些建的的非贪心操作符实现，先尝试去匹配短的，然后再去匹配长的。

断言传统的正则元字符 ^ 和\$可以看做其周围字符串的断言：^ 断言在其之前是一新行（或者一个字符串的开头），\$ 则断言下一个字符串是新行（或者一个字符串的结尾) 。Perl 使用了更多的断言，如 \b 断言其前一个字符是文字和数字，而其下一个则不是。Perl 还提供了前瞻断言，(?=re) 就断言当前位置之后的字符串可被正则 re 匹配，而且并不改变当前指向的字符串位置。(?<=re)则提供了逆序环视，与前瞻断言功能相反，是回看断言。

反向引用&nbsp;就像之前提到的，没有人知道怎么能够高效实现反向引用，而没有人能够证明这是不可能的。实际上，这个问题是&nbsp;NP-complete, 如果有人可以高效实现，那么这将成为计算机界轰动的大事，也将获得一百万美元大奖。 关于反向引用简单高效的实现，那就是不去实现它。但现在这个策略已经行不通了，很多用户越来越依赖反向引用，而且反向引用已经成了 POSIX 正则标准里的一部分了。尽管如此，还是需要在大部分情况下使用 Thompson 的 NFA 模拟算法，只有在出现反向引用的时候才选择其他实现。一个特别聪明的实现，是把这两者结合起来，反向引用的归反向引用。

反向引用与memoization&nbsp;Perl 使用 memoization 来尽可能防止在出现反向引用的时候引起指数爆炸，在理论上，其应该是可以达到和 NFA 方法相同的效果。但是 memoization 并没有完全解决这个问题，这需要的内存大概是文本长度和正则长度相乘之积。 memoization 同样没有解决反向引用栈空间的使用问题，它和文本长度线性相关，对于长文本，直接会耗尽栈空间。如下这个正则就运行不了：

    $ perl -e '("a" x 100000) =~ /^(ab?)*$/;'

Segmentation fault (core dumped) 
